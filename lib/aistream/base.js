import fetch from 'node-fetch';
import path from 'path';
import fs from 'fs';
import BotUtil from '../common/util.js';

/**
 * è½»é‡çº§æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—å™¨ï¼ˆBM25ç®—æ³•ï¼‰
 * é›¶ä¾èµ–é™çº§æ–¹æ¡ˆ
 */
class LightweightSimilarity {
  constructor() {
    this.idf = new Map();
    this.avgDocLength = 0;
    this.k1 = 1.5;
    this.b = 0.75;
  }

  tokenize(text) {
    // ä¸­æ–‡å­—ç¬¦çº§ + bigram
    const chars = text.split('');
    const bigrams = [];
    for (let i = 0; i < chars.length - 1; i++) {
      bigrams.push(chars[i] + chars[i + 1]);
    }
    return [...chars, ...bigrams];
  }

  calculateIDF(documents) {
    const docCount = documents.length;
    const termDocCount = new Map();

    for (const doc of documents) {
      const tokens = new Set(this.tokenize(doc));
      for (const token of tokens) {
        termDocCount.set(token, (termDocCount.get(token) || 0) + 1);
      }
    }

    for (const [term, count] of termDocCount) {
      this.idf.set(term, Math.log((docCount - count + 0.5) / (count + 0.5) + 1));
    }

    this.avgDocLength = documents.reduce((sum, doc) => 
      sum + this.tokenize(doc).length, 0) / docCount;
  }

  score(query, document) {
    const queryTokens = this.tokenize(query);
    const docTokens = this.tokenize(document);
    const docLength = docTokens.length;

    const termFreq = new Map();
    for (const token of docTokens) {
      termFreq.set(token, (termFreq.get(token) || 0) + 1);
    }

    let score = 0;
    for (const token of queryTokens) {
      const tf = termFreq.get(token) || 0;
      const idf = this.idf.get(token) || 0;
      const numerator = tf * (this.k1 + 1);
      const denominator = tf + this.k1 * (1 - this.b + this.b * (docLength / this.avgDocLength));
      score += idf * (numerator / denominator);
    }

    return score;
  }
}

/**
 * AIå·¥ä½œæµåŸºç±»
 */
export default class AIStream {
  constructor(options = {}) {
    this.name = options.name || 'base-stream';
    this.description = options.description || 'åŸºç¡€å·¥ä½œæµ';
    this.version = options.version || '1.0.0';
    this.author = options.author || 'unknown';
    this.priority = options.priority || 100;
    
    this.config = {
      enabled: true,
      temperature: 0.8,
      maxTokens: 6000,
      topP: 0.9,
      presencePenalty: 0.6,
      frequencyPenalty: 0.6,
      ...options.config
    };
    
    this.functionToggles = options.functionToggles || {};
    
    // Embeddingé…ç½®
    this.embeddingConfig = {
      enabled: false,
      provider: 'onnx', // onnx | hf | fasttext | api | lightweight
      maxContexts: 5,
      similarityThreshold: 0.6,
      cacheExpiry: 86400,
      cachePath: path.join(process.cwd(), 'data/models'),
      
      // ONNX Runtime é…ç½®
      onnxModel: 'Xenova/all-MiniLM-L6-v2',
      onnxQuantized: true,
      
      // Hugging Face Inference API é…ç½®
      hfToken: null,
      hfModel: 'sentence-transformers/all-MiniLM-L6-v2',
      
      // FastText é…ç½®
      fasttextModel: 'cc.zh.300.bin',
      
      // è‡ªå®šä¹‰ API é…ç½®
      apiUrl: null,
      apiKey: null,
      apiModel: 'text-embedding-3-small',
      
      ...options.embedding
    };
  }

  /**
   * åˆå§‹åŒ–å·¥ä½œæµ
   */
  async init() {
    if (!this.functions) {
      this.functions = new Map();
    }
    
    if (this.embeddingModel === undefined) {
      this.embeddingModel = null;
      this.embeddingReady = false;
      this.similarityCalculator = null;
      this.embeddingSession = null;
      this.tokenizer = null;
    }
    
    if (this.embeddingConfig.enabled && !this.embeddingReady) {
      await this.initEmbedding().catch(err => {
        BotUtil.makeLog('warn', `[${this.name}] Embeddingåˆå§‹åŒ–å¤±è´¥: ${err.message}`, 'AIStream');
      });
    }
  }

  /**
   * åˆå§‹åŒ–Embeddingæ¨¡å‹
   */
  async initEmbedding() {
    if (!this.embeddingConfig.enabled) {
      BotUtil.makeLog('debug', `[${this.name}] Embeddingæœªå¯ç”¨`, 'AIStream');
      return;
    }

    if (this.embeddingReady) {
      BotUtil.makeLog('debug', `[${this.name}] Embeddingå·²åˆå§‹åŒ–`, 'AIStream');
      return;
    }

    BotUtil.makeLog('info', `[${this.name}] ğŸš€ åˆå§‹åŒ–Embedding (${this.embeddingConfig.provider})...`, 'AIStream');

    try {
      switch (this.embeddingConfig.provider) {
        case 'lightweight':
          await this.initLightweightEmbedding();
          break;
        case 'onnx':
          await this.initONNXEmbedding();
          break;
        case 'hf':
          await this.initHFEmbedding();
          break;
        case 'fasttext':
          await this.initFastTextEmbedding();
          break;
        case 'api':
          await this.initAPIEmbedding();
          break;
        default:
          throw new Error(`æœªçŸ¥æä¾›å•†: ${this.embeddingConfig.provider}`);
      }
      
      BotUtil.makeLog('success', `[${this.name}] âœ… Embeddingåˆå§‹åŒ–æˆåŠŸ`, 'AIStream');
    } catch (error) {
      BotUtil.makeLog('error', `[${this.name}] âŒ Embeddingåˆå§‹åŒ–å¤±è´¥: ${error.message}`, 'AIStream');
      
      // é™çº§ç­–ç•¥é“¾
      const fallbackChain = ['onnx', 'hf', 'fasttext', 'api', 'lightweight'];
      const currentIndex = fallbackChain.indexOf(this.embeddingConfig.provider);
      
      for (let i = currentIndex + 1; i < fallbackChain.length; i++) {
        const fallbackProvider = fallbackChain[i];
        BotUtil.makeLog('info', `[${this.name}] ğŸ”„ å°è¯•é™çº§åˆ° ${fallbackProvider}...`, 'AIStream');
        
        try {
          this.embeddingConfig.provider = fallbackProvider;
          
          switch (fallbackProvider) {
            case 'onnx':
              await this.initONNXEmbedding();
              break;
            case 'hf':
              await this.initHFEmbedding();
              break;
            case 'fasttext':
              await this.initFastTextEmbedding();
              break;
            case 'api':
              await this.initAPIEmbedding();
              break;
            case 'lightweight':
              await this.initLightweightEmbedding();
              break;
          }
          
          BotUtil.makeLog('success', `[${this.name}] âœ… å·²é™çº§åˆ° ${fallbackProvider}`, 'AIStream');
          return;
        } catch (fallbackError) {
          BotUtil.makeLog('warn', `[${this.name}] âš ï¸ ${fallbackProvider} é™çº§å¤±è´¥: ${fallbackError.message}`, 'AIStream');
        }
      }
      
      // æ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥
      this.embeddingConfig.enabled = false;
      this.embeddingReady = false;
      throw new Error('æ‰€æœ‰Embeddingæ–¹æ¡ˆéƒ½å¤±è´¥ï¼Œå·²ç¦ç”¨åŠŸèƒ½');
    }
  }

  /**
   * åˆå§‹åŒ–è½»é‡çº§Embeddingï¼ˆBM25ç®—æ³•ï¼Œé›¶ä¾èµ–ï¼‰
   */
  async initLightweightEmbedding() {
    BotUtil.makeLog('info', `[${this.name}] ğŸ“ ä½¿ç”¨è½»é‡çº§BM25ç®—æ³•ï¼ˆé›¶ä¾èµ–ï¼‰`, 'AIStream');
    
    this.similarityCalculator = new LightweightSimilarity();
    this.embeddingReady = true;
    
    BotUtil.makeLog('success', `[${this.name}] âœ… è½»é‡çº§æ¨¡å¼å°±ç»ª`, 'AIStream');
  }

  /**
   * åˆå§‹åŒ–ONNX Runtime Embeddingï¼ˆæ¨èæ–¹æ¡ˆï¼‰
   */
  async initONNXEmbedding() {
    BotUtil.makeLog('info', `[${this.name}] ğŸ“¦ åŠ è½½ ONNX Runtime...`, 'AIStream');
    
    try {
      const ort = await import('onnxruntime-node');
      
      const modelName = this.embeddingConfig.onnxModel || 'Xenova/all-MiniLM-L6-v2';
      BotUtil.makeLog('info', `[${this.name}] ğŸ¤– åŠ è½½æ¨¡å‹: ${modelName}`, 'AIStream');
      
      // ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
      const cachePath = this.embeddingConfig.cachePath;
      if (!fs.existsSync(cachePath)) {
        fs.mkdirSync(cachePath, { recursive: true });
      }
      
      // ä¸‹è½½æˆ–åŠ è½½æ¨¡å‹
      const modelPath = await this.downloadONNXModel(modelName);
      
      BotUtil.makeLog('info', `[${this.name}] â³ åŠ è½½æ¨¡å‹æ–‡ä»¶...`, 'AIStream');
      const startTime = Date.now();
      
      this.embeddingSession = await ort.InferenceSession.create(modelPath, {
        executionProviders: ['cpu'],
        graphOptimizationLevel: 'all'
      });
      
      // åŠ è½½tokenizer
      await this.loadONNXTokenizer(modelName);
      
      const loadTime = ((Date.now() - startTime) / 1000).toFixed(2);
      this.embeddingReady = true;
      
      BotUtil.makeLog('success', `[${this.name}] âœ… ONNXæ¨¡å‹å°±ç»ª (è€—æ—¶: ${loadTime}ç§’)`, 'AIStream');
      
      // æµ‹è¯•æ¨¡å‹
      await this.testEmbeddingModel();
    } catch (error) {
      BotUtil.makeLog('error', `[${this.name}] âŒ ONNXåŠ è½½å¤±è´¥: ${error.message}`, 'AIStream');
      
      if (error.message.includes('Cannot find module')) {
        BotUtil.makeLog('info', `[${this.name}] ğŸ’¡ å®‰è£…: pnpm add onnxruntime-node -w`, 'AIStream');
      }
      
      throw error;
    }
  }

  /**
   * ä¸‹è½½ONNXæ¨¡å‹
   */
  async downloadONNXModel(modelName) {
    const cachePath = this.embeddingConfig.cachePath;
    const modelDir = path.join(cachePath, modelName.replace('/', '_'));
    const modelPath = path.join(modelDir, 'model_quantized.onnx');
    
    // å¦‚æœæ¨¡å‹å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
    if (fs.existsSync(modelPath)) {
      BotUtil.makeLog('debug', `[${this.name}] ğŸ“‚ ä½¿ç”¨ç¼“å­˜æ¨¡å‹: ${modelPath}`, 'AIStream');
      return modelPath;
    }
    
    // åˆ›å»ºæ¨¡å‹ç›®å½•
    if (!fs.existsSync(modelDir)) {
      fs.mkdirSync(modelDir, { recursive: true });
    }
    
    // ä¸‹è½½æ¨¡å‹
    BotUtil.makeLog('info', `[${this.name}] â¬‡ï¸ ä¸‹è½½æ¨¡å‹ (çº¦20-50MB)...`, 'AIStream');
    
    const modelUrl = `https://huggingface.co/${modelName}/resolve/main/onnx/model_quantized.onnx`;
    
    try {
      const response = await fetch(modelUrl);
      if (!response.ok) {
        throw new Error(`ä¸‹è½½å¤±è´¥: ${response.status}`);
      }
      
      const buffer = await response.arrayBuffer();
      fs.writeFileSync(modelPath, Buffer.from(buffer));
      
      BotUtil.makeLog('success', `[${this.name}] âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ`, 'AIStream');
      return modelPath;
    } catch (error) {
      throw new Error(`æ¨¡å‹ä¸‹è½½å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * åŠ è½½ONNX Tokenizerï¼ˆç®€åŒ–ç‰ˆï¼‰
   */
  async loadONNXTokenizer(modelName) {
    // ç®€åŒ–çš„tokenizerï¼Œä½¿ç”¨å­—ç¬¦çº§åˆ†è¯
    this.tokenizer = {
      encode: (text) => {
        // ç®€å•çš„å­—ç¬¦çº§tokenization
        const tokens = text.split('').map(c => c.charCodeAt(0));
        return tokens.slice(0, 512); // é™åˆ¶é•¿åº¦
      }
    };
    
    BotUtil.makeLog('debug', `[${this.name}] âœ… Tokenizerå°±ç»ª`, 'AIStream');
  }

  /**
   * åˆå§‹åŒ–Hugging Face Inference API
   */
  async initHFEmbedding() {
    const config = this.embeddingConfig;
    
    if (!config.hfToken) {
      throw new Error('æœªé…ç½®Hugging Face Token (éœ€è¦ hfToken)');
    }

    BotUtil.makeLog('info', `[${this.name}] ğŸ¤— é…ç½® Hugging Face API...`, 'AIStream');
    BotUtil.makeLog('info', `[${this.name}] ğŸ”‘ ä½¿ç”¨æ¨¡å‹: ${config.hfModel}`, 'AIStream');
    
    try {
      // åŠ¨æ€å¯¼å…¥
      const { HfInference } = await import('@huggingface/inference');
      this.embeddingModel = new HfInference(config.hfToken);
      
      // æµ‹è¯•è¿æ¥
      await this.testHFConnection();
      this.embeddingReady = true;
      
      BotUtil.makeLog('success', `[${this.name}] âœ… HF APIå°±ç»ª (å…è´¹)`, 'AIStream');
    } catch (error) {
      if (error.message.includes('Cannot find module')) {
        BotUtil.makeLog('info', `[${this.name}] ğŸ’¡ å®‰è£…: pnpm add @huggingface/inference -w`, 'AIStream');
      }
      throw error;
    }
  }

  /**
   * åˆå§‹åŒ–FastText
   */
  async initFastTextEmbedding() {
    BotUtil.makeLog('info', `[${this.name}] ğŸ“š åŠ è½½ FastText...`, 'AIStream');
    
    try {
      const FastText = await import('fasttext.js');
      
      const modelName = this.embeddingConfig.fasttextModel || 'cc.zh.300.bin';
      const modelPath = path.join(this.embeddingConfig.cachePath, modelName);
      
      if (!fs.existsSync(modelPath)) {
        BotUtil.makeLog('info', `[${this.name}] â¬‡ï¸ ä¸‹è½½FastTextæ¨¡å‹...`, 'AIStream');
        await this.downloadFastTextModel(modelName);
      }
      
      BotUtil.makeLog('info', `[${this.name}] â³ åŠ è½½æ¨¡å‹...`, 'AIStream');
      const startTime = Date.now();
      
      this.embeddingModel = new FastText.FastText();
      await this.embeddingModel.load(modelPath);
      
      const loadTime = ((Date.now() - startTime) / 1000).toFixed(2);
      this.embeddingReady = true;
      
      BotUtil.makeLog('success', `[${this.name}] âœ… FastTextå°±ç»ª (è€—æ—¶: ${loadTime}ç§’)`, 'AIStream');
      
      // æµ‹è¯•æ¨¡å‹
      await this.testEmbeddingModel();
    } catch (error) {
      BotUtil.makeLog('error', `[${this.name}] âŒ FastTextåŠ è½½å¤±è´¥: ${error.message}`, 'AIStream');
      
      if (error.message.includes('Cannot find module')) {
        BotUtil.makeLog('info', `[${this.name}] ğŸ’¡ å®‰è£…: pnpm add fasttext.js -w`, 'AIStream');
      }
      
      throw error;
    }
  }

  /**
   * ä¸‹è½½FastTextæ¨¡å‹
   */
  async downloadFastTextModel(modelName) {
    const cachePath = this.embeddingConfig.cachePath;
    const modelPath = path.join(cachePath, modelName);
    
    if (!fs.existsSync(cachePath)) {
      fs.mkdirSync(cachePath, { recursive: true });
    }
    
    // FastTextå®˜æ–¹æ¨¡å‹URL
    const modelUrl = `https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/${modelName}`;
    
    BotUtil.makeLog('info', `[${this.name}] â¬‡ï¸ ä¸‹è½½FastTextæ¨¡å‹ (çº¦500MBï¼Œè¯·è€å¿ƒç­‰å¾…)...`, 'AIStream');
    
    try {
      const response = await fetch(modelUrl);
      if (!response.ok) {
        throw new Error(`ä¸‹è½½å¤±è´¥: ${response.status}`);
      }
      
      const buffer = await response.arrayBuffer();
      fs.writeFileSync(modelPath, Buffer.from(buffer));
      
      BotUtil.makeLog('success', `[${this.name}] âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ`, 'AIStream');
    } catch (error) {
      throw new Error(`æ¨¡å‹ä¸‹è½½å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * åˆå§‹åŒ–è‡ªå®šä¹‰API Embedding
   */
  async initAPIEmbedding() {
    const config = this.embeddingConfig;
    
    if (!config.apiUrl || !config.apiKey) {
      throw new Error('æœªé…ç½®Embedding API (éœ€è¦ apiUrl å’Œ apiKey)');
    }

    BotUtil.makeLog('info', `[${this.name}] ğŸŒ é…ç½®API: ${config.apiUrl}`, 'AIStream');
    BotUtil.makeLog('info', `[${this.name}] ğŸ”‘ ä½¿ç”¨æ¨¡å‹: ${config.apiModel}`, 'AIStream');
    
    // æµ‹è¯•APIè¿æ¥
    await this.testAPIConnection();
    this.embeddingReady = true;
    
    BotUtil.makeLog('success', `[${this.name}] âœ… APIè¿æ¥æˆåŠŸ`, 'AIStream');
  }

  /**
   * æµ‹è¯•Embeddingæ¨¡å‹
   */
  async testEmbeddingModel() {
    try {
      BotUtil.makeLog('debug', `[${this.name}] ğŸ§ª æµ‹è¯•æ¨¡å‹...`, 'AIStream');
      const vector = await this.generateEmbedding('æµ‹è¯•æ–‡æœ¬');
      
      if (!vector || !Array.isArray(vector) || vector.length === 0) {
        throw new Error('æ¨¡å‹è¿”å›æ— æ•ˆå‘é‡');
      }
      
      BotUtil.makeLog('success', `[${this.name}] âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡ (ç»´åº¦: ${vector.length})`, 'AIStream');
    } catch (error) {
      throw new Error(`æ¨¡å‹æµ‹è¯•å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * æµ‹è¯•HF APIè¿æ¥
   */
  async testHFConnection() {
    try {
      const testVector = await this.generateHFEmbedding('test');
      if (!testVector || !Array.isArray(testVector) || testVector.length === 0) {
        throw new Error('HF APIè¿”å›æ— æ•ˆå‘é‡');
      }
      BotUtil.makeLog('debug', `[${this.name}] âœ… HFæµ‹è¯•é€šè¿‡ (ç»´åº¦: ${testVector.length})`, 'AIStream');
    } catch (error) {
      throw new Error(`HFæµ‹è¯•å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * æµ‹è¯•APIè¿æ¥
   */
  async testAPIConnection() {
    try {
      const testVector = await this.generateAPIEmbedding('test');
      if (!testVector || !Array.isArray(testVector) || testVector.length === 0) {
        throw new Error('APIè¿”å›æ— æ•ˆå‘é‡');
      }
      BotUtil.makeLog('debug', `[${this.name}] âœ… APIæµ‹è¯•é€šè¿‡ (ç»´åº¦: ${testVector.length})`, 'AIStream');
    } catch (error) {
      throw new Error(`APIæµ‹è¯•å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * ç”ŸæˆEmbeddingå‘é‡
   */
  async generateEmbedding(text) {
    if (!this.embeddingConfig.enabled || !text) {
      return null;
    }

    if (!this.embeddingReady) {
      BotUtil.makeLog('warn', `[${this.name}] âš ï¸ Embeddingæœªå°±ç»ª`, 'AIStream');
      return null;
    }

    try {
      switch (this.embeddingConfig.provider) {
        case 'lightweight':
          // è½»é‡çº§æ¨¡å¼ï¼šè¿”å›æ–‡æœ¬æœ¬èº«
          return text;
        case 'onnx':
          return await this.generateONNXEmbedding(text);
        case 'hf':
          return await this.generateHFEmbedding(text);
        case 'fasttext':
          return await this.generateFastTextEmbedding(text);
        case 'api':
          return await this.generateAPIEmbedding(text);
        default:
          return null;
      }
    } catch (error) {
      BotUtil.makeLog('error', `[${this.name}] âŒ ç”ŸæˆEmbeddingå¤±è´¥: ${error.message}`, 'AIStream');
      return null;
    }
  }

  /**
   * ä½¿ç”¨ONNX Runtimeç”ŸæˆEmbedding
   */
  async generateONNXEmbedding(text) {
    if (!this.embeddingSession || !this.tokenizer) {
      throw new Error('ONNXæ¨¡å‹æœªåŠ è½½');
    }

    try {
      const ort = await import('onnxruntime-node');
      
      // Tokenize
      const inputIds = this.tokenizer.encode(text);
      const attentionMask = new Array(inputIds.length).fill(1);
      
      // å¡«å……åˆ°å›ºå®šé•¿åº¦
      const maxLength = 512;
      while (inputIds.length < maxLength) {
        inputIds.push(0);
        attentionMask.push(0);
      }
      
      // åˆ›å»ºtensor
      const inputIdsTensor = new ort.Tensor('int64', BigInt64Array.from(inputIds.map(id => BigInt(id))), [1, maxLength]);
      const attentionMaskTensor = new ort.Tensor('int64', BigInt64Array.from(attentionMask.map(m => BigInt(m))), [1, maxLength]);
      
      // è¿è¡Œæ¨ç†
      const feeds = {
        input_ids: inputIdsTensor,
        attention_mask: attentionMaskTensor
      };
      
      const results = await this.embeddingSession.run(feeds);
      const outputTensor = results[Object.keys(results)[0]];
      
      // æå–embedding (mean pooling)
      const embeddings = Array.from(outputTensor.data);
      const embeddingDim = embeddings.length / maxLength;
      const meanEmbedding = new Array(embeddingDim).fill(0);
      
      let validTokens = 0;
      for (let i = 0; i < maxLength; i++) {
        if (attentionMask[i] === 1) {
          for (let j = 0; j < embeddingDim; j++) {
            meanEmbedding[j] += embeddings[i * embeddingDim + j];
          }
          validTokens++;
        }
      }
      
      // å¹³å‡åŒ–
      const result = meanEmbedding.map(v => v / validTokens);
      
      // å½’ä¸€åŒ–
      const norm = Math.sqrt(result.reduce((sum, v) => sum + v * v, 0));
      return result.map(v => v / norm);
    } catch (error) {
      throw new Error(`ONNXç”Ÿæˆå¤±è´¥: ${error.message}`);
    }
  }

  /**
   * ä½¿ç”¨Hugging Face APIç”ŸæˆEmbedding
   */
  async generateHFEmbedding(text) {
    if (!this.embeddingModel) {
      throw new Error('HFæ¨¡å‹æœªåŠ è½½');
    }

    try {
      const result = await this.embeddingModel.featureExtraction({
        model: this.embeddingConfig.hfModel,
        inputs: text
      });
      
      // HF APIè¿”å›çš„æ˜¯æ•°ç»„ï¼Œéœ€è¦æå–
      const embedding = Array.isArray(result) ? result : Array.from(result);
      return embedding;
    } catch (error) {
      if (error.message.includes('Rate limit')) {
        throw new Error('HF APIé€Ÿç‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•');
      }
      throw new Error(`HFç”Ÿæˆå¤±è´¥: ${error.message}`);
    }
  }

  /**
   * ä½¿ç”¨FastTextç”ŸæˆEmbedding
   */
  async generateFastTextEmbedding(text) {
    if (!this.embeddingModel) {
      throw new Error('FastTextæ¨¡å‹æœªåŠ è½½');
    }

    try {
      // FastTextç”Ÿæˆå¥å­å‘é‡
      const vector = await this.embeddingModel.getSentenceVector(text);
      return Array.from(vector);
    } catch (error) {
      throw new Error(`FastTextç”Ÿæˆå¤±è´¥: ${error.message}`);
    }
  }

  /**
   * ä½¿ç”¨è‡ªå®šä¹‰APIç”ŸæˆEmbedding
   */
  async generateAPIEmbedding(text) {
    const config = this.embeddingConfig;
    
    if (!config.apiUrl || !config.apiKey) {
      throw new Error('æœªé…ç½®API');
    }

    try {
      const response = await fetch(config.apiUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${config.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: config.apiModel || 'text-embedding-3-small',
          input: text,
          encoding_format: 'float'
        }),
        timeout: 10000
      });

      if (!response.ok) {
        const errorText = await response.text().catch(() => 'Unknown error');
        throw new Error(`APIé”™è¯¯ ${response.status}: ${errorText}`);
      }

      const result = await response.json();
      const embedding = result.data?.[0]?.embedding;
      
      if (!embedding || !Array.isArray(embedding)) {
        throw new Error('APIè¿”å›æ— æ•ˆæ•°æ®');
      }
      
      return embedding;
    } catch (error) {
      if (error.name === 'AbortError') {
        throw new Error('APIè¯·æ±‚è¶…æ—¶');
      }
      throw error;
    }
  }

  /**
   * è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
   */
  cosineSimilarity(vec1, vec2) {
    if (!vec1 || !vec2 || !Array.isArray(vec1) || !Array.isArray(vec2)) {
      return 0;
    }

    if (vec1.length !== vec2.length) {
      return 0;
    }

    let dotProduct = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (let i = 0; i < vec1.length; i++) {
      dotProduct += vec1[i] * vec2[i];
      norm1 += vec1[i] * vec1[i];
      norm2 += vec2[i] * vec2[i];
    }

    const denominator = Math.sqrt(norm1) * Math.sqrt(norm2);
    return denominator === 0 ? 0 : dotProduct / denominator;
  }

  /**
   * å­˜å‚¨æ¶ˆæ¯åˆ°Redis
   */
  async storeMessageWithEmbedding(groupId, message) {
    if (!this.embeddingConfig.enabled || typeof redis === 'undefined' || !redis) {
      return;
    }

    if (!this.embeddingReady) {
      return;
    }

    try {
      const key = `ai:embedding:${this.name}:${groupId}`;
      const messageText = `${message.nickname}: ${message.message}`;
      
      const embedding = await this.generateEmbedding(messageText);
      if (!embedding) {
        return;
      }

      const data = {
        message: messageText,
        embedding: embedding,
        userId: message.user_id,
        nickname: message.nickname,
        time: message.time || Date.now(),
        messageId: message.message_id
      };

      await redis.lPush(key, JSON.stringify(data));
      await redis.lTrim(key, 0, 99);
      await redis.expire(key, this.embeddingConfig.cacheExpiry);
      
      BotUtil.makeLog('debug', `[${this.name}] ğŸ’¾ å·²å­˜å‚¨: ${messageText.substring(0, 30)}...`, 'AIStream');
    } catch (error) {
      BotUtil.makeLog('error', `[${this.name}] âŒ å­˜å‚¨å¤±è´¥: ${error.message}`, 'AIStream');
    }
  }

  /**
   * æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
   */
  async retrieveRelevantContexts(groupId, query) {
    if (!this.embeddingConfig.enabled || typeof redis === 'undefined' || !redis) {
      return [];
    }

    if (!this.embeddingReady || !query) {
      return [];
    }

    try {
      const key = `ai:embedding:${this.name}:${groupId}`;
      const messages = await redis.lRange(key, 0, -1);
      
      if (!messages || messages.length === 0) {
        return [];
      }

      // è§£ææ¶ˆæ¯
      const parsedMessages = [];
      for (const msg of messages) {
        try {
          const data = JSON.parse(msg);
          if (data.embedding) {
            parsedMessages.push(data);
          }
        } catch (e) {
          continue;
        }
      }

      if (parsedMessages.length === 0) {
        return [];
      }

      // æ ¹æ®æä¾›å•†é€‰æ‹©ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•
      let scored = [];
      
      if (this.embeddingConfig.provider === 'lightweight') {
        // è½»é‡çº§æ¨¡å¼ï¼šä½¿ç”¨BM25
        const documents = parsedMessages.map(m => m.message);
        this.similarityCalculator.calculateIDF(documents);
        
        scored = parsedMessages.map(data => ({
          message: data.message,
          similarity: this.similarityCalculator.score(query, data.message) / 10, // å½’ä¸€åŒ–
          time: data.time,
          userId: data.userId,
          nickname: data.nickname
        }));
      } else {
        // å‘é‡æ¨¡å¼ï¼šä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
        const queryEmbedding = await this.generateEmbedding(query);
        if (!queryEmbedding) {
          return [];
        }

        scored = parsedMessages.map(data => ({
          message: data.message,
          similarity: this.cosineSimilarity(queryEmbedding, data.embedding),
          time: data.time,
          userId: data.userId,
          nickname: data.nickname
        }));
      }

      // è¿‡æ»¤å’Œæ’åº
      const filtered = scored.filter(s => s.similarity >= this.embeddingConfig.similarityThreshold);
      filtered.sort((a, b) => b.similarity - a.similarity);
      const results = filtered.slice(0, this.embeddingConfig.maxContexts);
      
      if (results.length > 0) {
        BotUtil.makeLog('debug', 
          `[${this.name}] ğŸ” æ£€ç´¢åˆ° ${results.length} æ¡ç›¸å…³ä¸Šä¸‹æ–‡ (æœ€é«˜: ${(results[0].similarity * 100).toFixed(1)}%)`,
          'AIStream'
        );
      }
      
      return results;
    } catch (error) {
      BotUtil.makeLog('error', `[${this.name}] âŒ æ£€ç´¢å¤±è´¥: ${error.message}`, 'AIStream');
      return [];
    }
  }

  /**
   * æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
   */
  async buildEnhancedContext(e, question, baseMessages) {
    if (!this.embeddingConfig.enabled || !this.embeddingReady) {
      return baseMessages;
    }

    const groupId = e.group_id || `private_${e.user_id}`;
    const query = typeof question === 'string' ? question : 
                  (question?.content || question?.text || '');

    if (!query) {
      return baseMessages;
    }

    try {
      const relevantContexts = await this.retrieveRelevantContexts(groupId, query);
      
      if (relevantContexts.length === 0) {
        return baseMessages;
      }

      const enhanced = [...baseMessages];
      const contextPrompt = [
        '\nã€ç›¸å…³å†å²å¯¹è¯ã€‘',
        relevantContexts.map((ctx, i) => 
          `${i + 1}. ${ctx.message.substring(0, 100)} (ç›¸å…³åº¦: ${(ctx.similarity * 100).toFixed(0)}%)`
        ).join('\n'),
        '\nä»¥ä¸Šæ˜¯ç›¸å…³å†å²å¯¹è¯ï¼Œå¯å‚è€ƒä½†ä¸è¦é‡å¤ã€‚\n'
      ].join('\n');

      if (enhanced[0]?.role === 'system') {
        enhanced[0].content += contextPrompt;
      } else {
        enhanced.unshift({
          role: 'system',
          content: contextPrompt
        });
      }

      BotUtil.makeLog('info', 
        `[${this.name}] âœ… æ£€ç´¢åˆ° ${relevantContexts.length} æ¡ç›¸å…³ä¸Šä¸‹æ–‡`, 
        'AIStream'
      );

      return enhanced;
    } catch (error) {
      BotUtil.makeLog('error', `[${this.name}] âŒ æ„å»ºä¸Šä¸‹æ–‡å¤±è´¥: ${error.message}`, 'AIStream');
      return baseMessages;
    }
  }

  // ========== åŠŸèƒ½ç®¡ç† ==========

  registerFunction(name, options = {}) {
    const {
      handler,
      prompt = '',
      parser = null,
      enabled = true,
      permission = null,
      description = ''
    } = options;

    this.functions.set(name, {
      name,
      handler,
      prompt,
      parser,
      enabled: this.functionToggles[name] ?? enabled,
      permission,
      description
    });

    BotUtil.makeLog('debug', `[${this.name}] ğŸ“ æ³¨å†ŒåŠŸèƒ½: ${name}`, 'AIStream');
  }

  isFunctionEnabled(name) {
    const func = this.functions.get(name);
    return func?.enabled ?? false;
  }

  toggleFunction(name, enabled) {
    const func = this.functions.get(name);
    if (func) {
      func.enabled = enabled;
      this.functionToggles[name] = enabled;
    }
  }

  getEnabledFunctions() {
    return Array.from(this.functions.values()).filter(f => f.enabled);
  }

  buildSystemPrompt(context) {
    throw new Error('buildSystemPromptéœ€è¦å­ç±»å®ç°');
  }

  buildFunctionsPrompt() {
    const enabledFuncs = this.getEnabledFunctions();
    if (enabledFuncs.length === 0) return '';

    const prompts = enabledFuncs
      .filter(f => f.prompt)
      .map(f => f.prompt)
      .join('\n');

    return prompts ? `\nã€åŠŸèƒ½åˆ—è¡¨ã€‘\n${prompts}` : '';
  }

  async buildChatContext(e, question) {
    throw new Error('buildChatContextéœ€è¦å­ç±»å®ç°');
  }

  parseFunctions(text, context = {}) {
    let cleanText = text;
    const allFunctions = [];
    
    for (const func of this.functions.values()) {
      if (!func.enabled || !func.parser) continue;
      
      try {
        const result = func.parser(cleanText, context);
        if (result.functions && result.functions.length > 0) {
          allFunctions.push(...result.functions);
        }
        if (result.cleanText !== undefined) {
          cleanText = result.cleanText;
        }
      } catch (error) {
        BotUtil.makeLog('error', `âŒ åŠŸèƒ½è§£æå¤±è´¥[${func.name}]: ${error.message}`, 'AIStream');
      }
    }
    
    return { functions: allFunctions, cleanText };
  }

  async executeFunction(type, params, context) {
    const func = this.functions.get(type);
    
    if (!func || !func.enabled) {
      return;
    }
    
    if (func.permission && !(await this.checkPermission(func.permission, context))) {
      return;
    }
    
    try {
      if (func.handler) {
        await func.handler(params, context);
      }
    } catch (error) {
      BotUtil.makeLog('error', `âŒ åŠŸèƒ½æ‰§è¡Œå¤±è´¥[${type}]: ${error.message}`, 'AIStream');
    }
  }

  async checkPermission(permission, context) {
    const { e } = context;
    if (!e?.isGroup) return false;
    if (e.isMaster) return true;

    try {
      const member = e.group?.pickMember(e.self_id);
      const info = await member?.getInfo().catch(() => null);
      const role = info?.role || 'member';

      switch (permission) {
        case 'admin':
        case 'mute':
          return role === 'owner' || role === 'admin';
        case 'owner':
          return role === 'owner';
        default:
          return true;
      }
    } catch (error) {
      return false;
    }
  }

  async callAI(messages, apiConfig = {}) {
    const config = { ...this.config, ...apiConfig };
    
    if (!config.baseUrl || !config.apiKey) {
      throw new Error('æœªé…ç½®AI API');
    }

    try {
      const response = await fetch(`${config.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${config.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: config.model || config.chatModel || 'gpt-3.5-turbo',
          messages,
          temperature: config.temperature,
          max_tokens: config.maxTokens,
          top_p: config.topP,
          presence_penalty: config.presencePenalty,
          frequency_penalty: config.frequencyPenalty,
          stream: false
        }),
        timeout: config.timeout || 30000
      });

      if (!response.ok) {
        throw new Error(`APIé”™è¯¯: ${response.status}`);
      }

      const result = await response.json();
      return result.choices?.[0]?.message?.content || null;
    } catch (error) {
      BotUtil.makeLog('error', `âŒ AIè°ƒç”¨å¤±è´¥: ${error.message}`, 'AIStream');
      return null;
    }
  }

  async execute(e, question, config) {
    try {
      const context = { e, question, config };
      const baseMessages = await this.buildChatContext(e, question);
      const messages = await this.buildEnhancedContext(e, question, baseMessages);
      const response = await this.callAI(messages, config);
      
      if (!response) {
        return null;
      }
      
      const { functions, cleanText } = this.parseFunctions(response, context);
      
      for (const func of functions) {
        await this.executeFunction(func.type, func.params, context);
      }
      
      // å­˜å‚¨Botçš„å›å¤
      if (this.embeddingConfig.enabled && cleanText) {
        const groupId = e.group_id || `private_${e.user_id}`;
        this.storeMessageWithEmbedding(groupId, {
          user_id: e.self_id,
          nickname: Bot.nickname || 'Bot',
          message: cleanText,
          message_id: Date.now().toString(),
          time: Date.now()
        }).catch(() => {});
      }
      
      return cleanText;
    } catch (error) {
      BotUtil.makeLog('error', `âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥[${this.name}]: ${error.message}`, 'AIStream');
      return null;
    }
  }

  async process(e, question, apiConfig = {}) {
    try {
      return await this.execute(e, question, apiConfig);
    } catch (error) {
      BotUtil.makeLog('error', `âŒ å·¥ä½œæµå¤„ç†å¤±è´¥[${this.name}]: ${error.message}`, 'AIStream');
      return null;
    }
  }

  getInfo() {
    return {
      name: this.name,
      description: this.description,
      version: this.version,
      author: this.author,
      priority: this.priority,
      embedding: {
        enabled: this.embeddingConfig.enabled,
        provider: this.embeddingConfig.provider,
        ready: this.embeddingReady,
        model: this.embeddingConfig.onnxModel || this.embeddingConfig.hfModel || this.embeddingConfig.apiModel,
        maxContexts: this.embeddingConfig.maxContexts,
        threshold: this.embeddingConfig.similarityThreshold
      },
      functions: Array.from(this.functions.values()).map(f => ({
        name: f.name,
        description: f.description,
        enabled: f.enabled,
        permission: f.permission
      }))
    };
  }

  async cleanup() {
    BotUtil.makeLog('info', `[${this.name}] ğŸ§¹ æ¸…ç†èµ„æº...`, 'AIStream');
    
    // æ¸…ç†ONNX Session
    if (this.embeddingSession) {
      try {
        // ONNX Runtimeçš„sessionæ²¡æœ‰æ˜¾å¼disposeæ–¹æ³•ï¼Œè®©GCå¤„ç†
        this.embeddingSession = null;
        BotUtil.makeLog('debug', `[${this.name}] âœ… ONNX Sessionå·²é‡Šæ”¾`, 'AIStream');
      } catch (error) {
        BotUtil.makeLog('warn', `[${this.name}] âš ï¸ é‡Šæ”¾å¤±è´¥: ${error.message}`, 'AIStream');
      }
    }
    
    // æ¸…ç†å…¶ä»–æ¨¡å‹
    if (this.embeddingModel && typeof this.embeddingModel.dispose === 'function') {
      try {
        await this.embeddingModel.dispose();
        BotUtil.makeLog('debug', `[${this.name}] âœ… æ¨¡å‹å·²é‡Šæ”¾`, 'AIStream');
      } catch (error) {
        BotUtil.makeLog('warn', `[${this.name}] âš ï¸ é‡Šæ”¾å¤±è´¥: ${error.message}`, 'AIStream');
      }
    }
    
    this.embeddingModel = null;
    this.embeddingReady = false;
    this.tokenizer = null;
    
    BotUtil.makeLog('success', `[${this.name}] âœ… æ¸…ç†å®Œæˆ`, 'AIStream');
  }
}