# ========================================
# OpenAI 官方 LLM 配置
# ========================================
# OpenAI Chat Completions 官方接口
# 工厂类：OpenAILLMClient
# 接口文档：https://platform.openai.com/docs/api-reference/chat
# 配置文件实际路径：data/server_bots/{port}/openai_llm.yaml
# ----------------------------------------
# 基础
# ----------------------------------------
# enabled: 是否启用该提供商
enabled: true
# baseUrl: 默认官方地址，可改为代理或中转
baseUrl: "https://api.openai.com/v1"
# apiKey: OpenAI API Key（必填）
apiKey: ""
# ----------------------------------------
# 模型与生成参数
# ----------------------------------------
# model: 模型名称
model: "gpt-4"
# temperature: 温度 0～2，越高越随机
temperature: 0.7
# maxTokens: 最大生成 token 数
maxTokens: 4000
# topP: 核采样 0～1
topP: 1
# presencePenalty: 存在惩罚 -2～2
presencePenalty: 0
# frequencyPenalty: 频率惩罚 -2～2
frequencyPenalty: 0
# ----------------------------------------
# 超时与能力
# ----------------------------------------
# timeout: 单次请求超时（毫秒）
timeout: 60000
# enableStream: 是否允许流式输出
enableStream: true
# enableTools: 启用后注入 MCP 工具（OpenAI tools/tool_calls）
enableTools: true
# ----------------------------------------
# 代理（可选）
# ----------------------------------------
proxy:
  # enabled: 是否启用代理
  enabled: false
  # url: 代理地址，如 http://127.0.0.1:7890 或 socks5://127.0.0.1:1080
  url: ""
