# ========================================
# Azure OpenAI LLM 配置
# ========================================
# Azure OpenAI 服务，按部署名调用
# 工厂类：AzureOpenAILLMClient
# 路径形式：/openai/deployments/{deployment}/chat/completions?api-version=xxx
# 配置文件实际路径：data/server_bots/{port}/azure_openai_llm.yaml
# ----------------------------------------
# 基础
# ----------------------------------------
# enabled: 是否启用该提供商
enabled: true
# baseUrl: 如 https://{resource}.openai.azure.com
baseUrl: "https://{resource}.openai.azure.com"
# apiKey: Azure 门户中该资源的密钥
apiKey: ""
# deployment: 部署名称（必填），与 path 中的 deployment 对应
deployment: ""
# apiVersion: 接口版本，如 2024-02-15-preview
apiVersion: "2024-02-15-preview"
# model: 模型名称（与 deployment 对应）
model: "gpt-4"
# temperature: 温度 0～2
temperature: 0.7
# maxTokens: 最大生成 token 数
maxTokens: 4000
# timeout: 单次请求超时（毫秒）
timeout: 60000
# enableStream: 是否允许流式输出
enableStream: true
# enableTools: 启用后注入 MCP 工具
enableTools: true
# ----------------------------------------
# 代理（可选）
# ----------------------------------------
proxy:
  # enabled: 是否启用代理
  enabled: false
  # url: 代理地址
  url: ""
